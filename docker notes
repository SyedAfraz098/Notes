ğŸ§± 1. Your 1 GB project â€” what it contains

Letâ€™s say your project folder is 1 GB.
That size might include:

Source code (text files)

Compiled binaries

Dependencies (node_modules, venv, vendor, etc.)

Logs or build artifacts

Some large media files, maybe

Now, when you make a Docker image from this project, the resulting image might be smaller â€” or larger â€” depending on what you include.

âš™ï¸ 2. What Docker actually stores

A Docker image is a set of filesystem layers, not an exact zip of your project folder.

When you build your image (with a Dockerfile), Docker only includes:

What you copy into the image (via COPY or ADD)

Whatâ€™s installed during RUN commands

Plus the base image layers (e.g. ubuntu:22.04, python:3.11-slim, etc.)

So if you donâ€™t copy unnecessary files (like logs, .git, build caches, test data), your final image can be much smaller than your raw project folder.

ğŸ§® 3. Kernel, drivers, GUI, etc.

These are not included in any Docker image.
They come from the host machine running the Docker daemon.

So:

No kernel inside the image (it uses host kernel)

No device drivers (host provides them)

No GUI or system services (unless you explicitly add them)

No bootloader or firmware

This is why even a base OS image is so small â€” Docker images are userland only.

ğŸª„ 4. Why your image can be smaller than your project

Hereâ€™s why your 1 GB project can shrink when containerized:

You exclude temporary files using .dockerignore

You use a slim base image (python:3.11-slim instead of ubuntu)

You only copy built artifacts, not the entire source tree

You run build steps in intermediate layers (then discard them using multi-stage builds)

Example:

# Build stage
FROM node:22 AS builder
WORKDIR /app
COPY package*.json ./
RUN npm install
COPY . .
RUN npm run build

# Final runtime image (much smaller)
FROM node:22-slim
WORKDIR /app
COPY --from=builder /app/dist ./
CMD ["node", "index.js"]


ğŸ‘‰ The final image might be a few hundred MB, even if your raw project folder is >1 GB.

ğŸ§  Step 1: What is a Dockerfile?

A Dockerfile is just a set of instructions telling Docker how to build an image.

Think of it like a recipe for your environment.

Example:

# Example Dockerfile
FROM ubuntu:22.04
RUN apt update && apt install -y python3
COPY . /app
WORKDIR /app
CMD ["python3", "main.py"]


Each line:

FROM â†’ base image (starting point)

RUN â†’ execute commands in build phase

COPY â†’ copy project files into image

WORKDIR â†’ set working directory

CMD â†’ what runs when container starts

ğŸ§± Step 2: The architecture for your example

We have 3 main parts:

Backend â€” Java Spring Boot (does CRUD)

Database â€” MySQL

Frontend â€” JavaScript (React/Vue/Angular)

AWS S3 â€” (external, no container needed; app accesses via SDK)

Weâ€™ll containerize:

Backend (Dockerfile)

Frontend (Dockerfile)

Database (use official MySQL image)

And then use Docker Compose to run them together.

âš™ï¸ Step 3: Example backend â€” Spring Boot + MySQL + S3
ğŸ“ Folder structure
myapp/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ src/...
â”‚   â”œâ”€â”€ pom.xml
â”‚   â””â”€â”€ target/myapp.jar
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ src/...
â”œâ”€â”€ docker-compose.yml

ğŸ³ Backend Dockerfile (Spring Boot)
# Stage 1: Build the JAR file
FROM maven:3.9.5-eclipse-temurin-17 AS builder

WORKDIR /app
COPY pom.xml .
COPY src ./src
RUN mvn clean package -DskipTests

# Stage 2: Create lightweight runtime image
FROM eclipse-temurin:17-jdk-jammy

WORKDIR /app
COPY --from=builder /app/target/myapp.jar .
EXPOSE 8080

# Set environment variables for MySQL and AWS S3
ENV SPRING_DATASOURCE_URL=jdbc:mysql://mysql:3306/mydb
ENV SPRING_DATASOURCE_USERNAME=root
ENV SPRING_DATASOURCE_PASSWORD=root
ENV AWS_REGION=us-east-1

CMD ["java", "-jar", "myapp.jar"]


ğŸ§© Explanation:

We use multi-stage build: first build the JAR using Maven, then copy it into a smaller runtime image.

Environment variables are placeholders â€” theyâ€™ll come from docker-compose.yml.

MySQL host is mysql (Docker Compose network will resolve this automatically).

ğŸ–¥ï¸ Frontend Dockerfile (React example)
# Stage 1: Build static files
FROM node:20 AS builder
WORKDIR /app
COPY package*.json ./
RUN npm install
COPY . .
RUN npm run build

# Stage 2: Serve static files
FROM nginx:alpine
COPY --from=builder /app/dist /usr/share/nginx/html
EXPOSE 80


ğŸ§© Explanation:

Uses Node to build frontend files (npm run build).

Copies built static files into an Nginx container to serve them.

ğŸ—„ï¸ Database (MySQL)

Weâ€™ll use the official image â€” no Dockerfile needed.

ğŸ§© Step 4: docker-compose.yml â€” to tie them all together
version: "3.9"
services:
  backend:
    build: ./backend
    container_name: spring_backend
    ports:
      - "8080:8080"
    environment:
      - SPRING_DATASOURCE_URL=jdbc:mysql://mysql:3306/mydb
      - SPRING_DATASOURCE_USERNAME=root
      - SPRING_DATASOURCE_PASSWORD=root
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
    depends_on:
      - mysql

  frontend:
    build: ./frontend
    container_name: frontend_app
    ports:
      - "3000:80"
    depends_on:
      - backend

  mysql:
    image: mysql:8.0
    container_name: mysql_db
    environment:
      - MYSQL_ROOT_PASSWORD=root
      - MYSQL_DATABASE=mydb
    volumes:
      - db_data:/var/lib/mysql
    ports:
      - "3306:3306"

volumes:
  db_data:


ğŸ§© Explanation:

Defines three services (backend, frontend, mysql)

Automatically creates a shared network

Containers communicate using service names (e.g. mysql instead of localhost)

AWS credentials can be injected via environment variables

ğŸ§ª Step 5: Build and run everything
docker compose up --build

ğŸ§± 3ï¸âƒ£ Usual Flow / Structure of a Dockerfile

Hereâ€™s the logical flow most Dockerfiles follow:

Base image
Choose minimal and relevant image (e.g. ubuntu, alpine, python, openjdk, etc.)

Metadata (optional)
Example: who built it, purpose, version.

Environment setup
Install tools, dependencies, environment variables.

Working directory
Set where the appâ€™s files will live.

Copy source code
Copy your project files from host into container.

Install dependencies
Run build commands like npm install, mvn package, pip install, etc.

Expose ports
So you can access your app externally.

Run command
Specify how to start your application (e.g. CMD ["java", "-jar", "app.jar"]).

ğŸ§¾ Common Dockerfile Skeleton Template
# Step 1: Base image
FROM ubuntu:22.04

# Step 2: Metadata
LABEL maintainer="yourname@example.com"
LABEL description="My App Docker Image"

# Step 3: Environment variables
ENV APP_HOME=/app
ENV LANG=C.UTF-8

# Step 4: Set working directory
WORKDIR $APP_HOME

# Step 5: Copy files
COPY . .

# Step 6: Install dependencies
RUN apt update && apt install -y python3 python3-pip \
    && pip install -r requirements.txt \
    && rm -rf /var/lib/apt/lists/*

# Step 7: Expose ports
EXPOSE 5000

# Step 8: Run the application
CMD ["python3", "app.py"]

| Step           | Question to ask                               | Example                                     |
| -------------- | --------------------------------------------- | ------------------------------------------- |
| 1ï¸âƒ£ Base Image | What language/runtime do I need?              | `openjdk:17`, `node:20`, `python:3.11-slim` |
| 2ï¸âƒ£ Setup      | What dependencies/tools do I need to install? | `RUN apt-get install -y curl git`           |
| 3ï¸âƒ£ Copy code  | What source files are needed?                 | `COPY . /app`                               |
| 4ï¸âƒ£ Build      | Do I need to compile or bundle something?     | `RUN mvn package`, `RUN npm run build`      |
| 5ï¸âƒ£ Expose     | Which port does my app listen on?             | `EXPOSE 8080`                               |
| 6ï¸âƒ£ Run        | What command starts my app?                   | `CMD ["java", "-jar", "app.jar"]`           |


ğŸ§ª 5ï¸âƒ£ Example for a Java Spring Boot Project

# Step 1: Use JDK image
FROM openjdk:17-jdk-slim

# Step 2: Set work directory
WORKDIR /app

# Step 3: Copy JAR file from host
COPY target/myapp.jar /app/myapp.jar

# Step 4: Expose port
EXPOSE 8080

# Step 5: Run app
CMD ["java", "-jar", "myapp.jar"]

ğŸ§  6ï¸âƒ£ Tips for Writing Efficient Dockerfiles

âœ… Use .dockerignore â€” exclude unnecessary files like .git, node_modules, logs, etc.
âœ… Use multi-stage builds â€” build big stuff, then copy only the final result.
âœ… Use slim/alpine base images â€” e.g., python:3.11-slim, openjdk:17-jdk-slim.
âœ… Donâ€™t install unnecessary tools â€” keep image lean.
âœ… Use ENV for config values â€” not hard-coded paths.
âœ… Order layers smartly â€” least frequently changed steps first (caches better).


ğŸ’¡ Analogy

Think of Dockerfile as a setup script that never forgets a step.
Instead of giving someone a 10-step setup document, you just give them the Dockerfile.

| Concept      | Manual setup         | Dockerfile                 |
| ------------ | -------------------- | -------------------------- |
| OS           | You install it       | Docker pulls it            |
| Dependencies | You install manually | `RUN` or `FROM` handles it |
| Code copy    | You upload manually  | `COPY` instruction         |
| Port setup   | OS firewall config   | `EXPOSE`                   |
| Run command  | You type manually    | `CMD`                      |


1ï¸âƒ£ What is a Multi-Stage Build?

A multi-stage build is a way to create smaller, cleaner Docker images
by using multiple FROM instructions in the same Dockerfile.

Each FROM line starts a new â€œstage,â€ and you can copy files from one stage to another.

The goal:
ğŸ‘‰ Use one stage for building or compiling
ğŸ‘‰ Use another stage for running your app â€” without all the extra build tools.

1ï¸âƒ£ What is a "Layer" in Docker?

Every line in a Dockerfile creates a new layer.
Think of each layer as a snapshot of your filesystem at that step.

Example:

FROM ubuntu:22.04          # Layer 1
RUN apt-get update          # Layer 2
RUN apt-get install -y openjdk-17-jdk  # Layer 3
WORKDIR /app                # Layer 4
COPY pom.xml .              # Layer 5
RUN mvn dependency:go-offline # Layer 6
COPY src ./src              # Layer 7
RUN mvn clean package       # Layer 8
CMD ["java", "-jar", "app.jar"] # Layer 9


Each line = one layer in the final image.

âœ… So your Docker image isnâ€™t one big file â€” itâ€™s a stack of layers layered on top of each other (like a cake ğŸ°).

ğŸ§  2ï¸âƒ£ What does Docker cache?

When you build an image, Docker stores these layers on your machine in a cache.

If you rebuild the same image later:

Docker checks if a step has changed since the last build.

If not, it reuses the cached layer instead of redoing the work.

This is called layer caching.

ğŸª„ Example:

Letâ€™s build this once:

docker build -t myapp:1.0 .


Now if you build again immediately:

docker build -t myapp:1.1 .


Output will show:

 => [2/8] RUN apt-get update                         Using cache
 => [3/8] RUN apt-get install -y openjdk-17-jdk      Using cache
 => [4/8] WORKDIR /app                               Using cache
 => [5/8] COPY pom.xml .                             Using cache
 => [6/8] RUN mvn dependency:go-offline              Using cache
 => [7/8] COPY src ./src                             5.4s
 => [8/8] RUN mvn clean package                      20.5s


See?
Steps 1â€“6 are reused from cache
Steps 7â€“8 rebuild (because code changed).

âœ… Docker only rebuilds layers after the first changed layer.

âš™ï¸ 3ï¸âƒ£ How Docker decides whether to reuse cache

Docker reuses a cached layer if:

The command (RUN, COPY, etc.) is identical

The files involved havenâ€™t changed

The parent layer (below it) didnâ€™t change

As soon as one step changes, every step after it is rebuilt.

ğŸ’¡ Example:
COPY pom.xml .      # Step 1
RUN mvn dependency:go-offline
COPY src ./src      # Step 2
RUN mvn clean package


If you change pom.xml, the cached layer for dependencies is invalidated.
So both the dependency installation and subsequent steps are rebuilt.

If you only change source code (src/), the dependency layers are cached and reused â€” only compilation happens again.

âœ… Thatâ€™s why we place COPY pom.xml before COPY src â€” to maximize caching efficiency.

ğŸ—ï¸ 4ï¸âƒ£ Why multi-stage builds make this even better

In a multi-stage Dockerfile:

# Stage 1: build
FROM maven:3.9 AS builder
WORKDIR /app
COPY pom.xml .
RUN mvn dependency:go-offline
COPY src ./src
RUN mvn clean package -DskipTests

# Stage 2: runtime
FROM eclipse-temurin:17-jdk
WORKDIR /app
COPY --from=builder /app/target/app.jar .
CMD ["java", "-jar", "app.jar"]


âœ… When you rebuild:

Docker reuses the cached mvn dependency:go-offline layer

Only recompiles changed source files

Produces a small final image (runtime only, no Maven)

So your builds are faster
and your final image is smaller (no build tools).

ğŸ§± 5ï¸âƒ£ What we usually ignore (to keep cache valid)

You donâ€™t want unnecessary rebuilds just because of unimportant file changes.

So developers ignore these in .dockerignore file (same idea as .gitignore):

target/
.git/
.idea/
.vscode/
*.log
*.tmp
node_modules/


âœ… This prevents Docker from thinking â€œsomething changedâ€ when in fact itâ€™s just build artifacts or temp files.

If you donâ€™t ignore them, Docker sees a different checksum and rebuilds everything unnecessarily.

| Layer type                                        | Usually cached? | Reason                 |
| ------------------------------------------------- | --------------- | ---------------------- |
| Base OS (`FROM ubuntu`)                           | âœ… Yes           | Rarely changes         |
| Package installation (`RUN apt install ...`)      | âœ… Yes           | Deterministic command  |
| Dependency download (`mvn dependency:go-offline`) | âœ… Yes           | pom.xml rarely changes |
| Source code copy (`COPY src`)                     | âŒ No            | Changes frequently     |
| Build step (`RUN mvn package`)                    | âŒ No            | Needs new jar          |
| Runtime setup (`CMD`, `ENTRYPOINT`)               | âœ… Yes           | Static command         |


1ï¸âƒ£ What does â€œruntimeâ€ mean in programming?

A runtime is basically the environment that your program needs to run.

It includes:

The interpreter or virtual machine

The standard libraries

And sometimes extra system components or configurations your language expects

Itâ€™s like the â€œengineâ€ your code needs to actually execute.

âš™ï¸ Real-world analogy

If your code is a car, the runtime is the engine.
Without an engine, you just have metal and wheels â€” it wonâ€™t move.

| Language         | What you ship   | Needs runtime/interpreter? | Why                                     |
| ---------------- | --------------- | -------------------------- | --------------------------------------- |
| **Java**         | `.jar` bytecode | âœ… Yes (JVM)                | Bytecode isnâ€™t native                   |
| **Python**       | `.py` scripts   | âœ… Yes (Python interpreter) | Code is interpreted                     |
| **Node.js (JS)** | `.js` files     | âœ… Yes (Node runtime)       | JS runs on V8 engine                    |
| **Go**           | Compiled binary | âŒ No                       | Compiled to native machine code         |
| **C/C++**        | Compiled binary | âŒ (Mostly)                 | Runs directly on CPU (linked libs only) |



5ï¸âƒ£ How this affects Docker images

Because Java/Python need runtimes, their Docker images include those runtimes:

Java image:
FROM openjdk:17-jdk-slim
COPY target/app.jar .
CMD ["java", "-jar", "app.jar"]

Python image:
FROM python:3.11-slim
COPY app.py .
CMD ["python", "app.py"]

| Concept                         | Meaning                                                                                         |
| ------------------------------- | ----------------------------------------------------------------------------------------------- |
| **Runtime**                     | Software layer that runs your program (interpreter or VM)                                       |
| **Java Runtime (JRE)**          | Runs `.jar` bytecode on JVM                                                                     |
| **Python Runtime**              | Executes `.py` scripts with interpreter                                                         |
| **Go Runtime**                  | Minimal â€” code compiles into self-contained binary                                              |
| **Why Go doesnâ€™t need runtime** | It compiles to native machine code (includes everything it needs)                               |
| **Impact on Docker**            | Java/Python images are larger because they include runtimes; Go can use `scratch` (no runtime). |

Java/Python need a runtime because your code doesnâ€™t run directly on the CPU.
Go doesnâ€™t â€” it becomes a native executable.

What is a distroless image?

The problem with normal base images

Most Docker images are based on full Linux distributions like Ubuntu, Debian, or Alpine.

For example:

FROM ubuntu:22.04
RUN apt-get update && apt-get install -y openjdk-17-jdk


âœ… Pros:

Easy to use

You get all the usual Linux tools (bash, curl, apt, etc.)

âŒ Cons:

Bigger image size (hundreds of MBs)

Contains many unnecessary packages (like vim, ls, grep, etc.)

Larger attack surface (more potential vulnerabilities)

Harder to keep secure and minimal

Distroless = â€œdistribution-lessâ€.
Itâ€™s a Docker image that contains only your application and its runtime â€” no full OS like Ubuntu or Debian.

ğŸ‘‰ It means:

No apt-get

No bash

No package manager

No shell tools

Just your app + what it needs to run (e.g. JVM, Python runtime, or compiled binary).

So itâ€™s not based on any Linux distro, even though it still uses the Linux kernel when running as a container.

3ï¸âƒ£ Example â€” Java app
Normal image
FROM openjdk:17-jdk-slim
COPY target/app.jar /app.jar
CMD ["java", "-jar", "/app.jar"]


Base: Debian slim (still has some OS)

Size: ~200â€“300 MB

Includes shell, apt, etc.

Distroless image
FROM gcr.io/distroless/java17
COPY target/app.jar /app.jar
CMD ["app.jar"]


Base: distroless/java17 (Googleâ€™s minimal runtime)

Size: ~80 MB

No shell, no package manager, minimal attack surface.

âœ… It still runs perfectly â€” because the JVM is included, but nothing else.

| Benefit                  | Explanation                                        |
| ------------------------ | -------------------------------------------------- |
| **ğŸ§± Smaller images**    | Only runtime + app, no OS packages                 |
| **ğŸ”’ More secure**       | No package manager, no shell â†’ less attack surface |
| **âš¡ Faster startup**     | Smaller layers = quicker pull/start                |
| **ğŸ” More reproducible** | Fewer moving parts, consistent builds              |
| **ğŸ“¦ Great for CI/CD**   | Ideal for production and serverless workloads      |

| Limitation                | Why it matters                                                                           |
| ------------------------- | ---------------------------------------------------------------------------------------- |
| âŒ No shell (`bash`, `sh`) | You canâ€™t `docker exec -it <container> /bin/bash`                                        |
| âŒ No package manager      | You canâ€™t install anything after build                                                   |
| âŒ Harder debugging        | You must use logs or sidecar containers                                                  |
| âŒ More complex builds     | You usually need multi-stage builds (build in one stage, copy to distroless final stage) |

So, what happens in a multi-stage Docker build?

You split your process into two stages:

Stage 1: Builder

Uses a full environment (like Maven, Node, etc.)

Installs all dependencies

Compiles the code

Produces the final artifact (like app.jar, dist/, binary, etc.)

Example:

FROM maven:3.9.5-eclipse-temurin-17 AS builder
WORKDIR /app
COPY . .
RUN mvn clean package -DskipTests


âœ… You need the full Maven + JDK here to build the app.

Stage 2: Runtime

You start from a small, clean base (like Distroless, Alpine, or scratch)

You copy only the artifact from the builder

You run it using just the runtime

Example:

FROM gcr.io/distroless/java17
COPY --from=builder /app/target/app.jar /app.jar
CMD ["app.jar"]


âœ… Only the .jar + JVM runtime â†’ everything else is gone.


Think of it like this:
Step	Analogy
Builder stage	Like your developer laptop â€” full of compilers, editors, tools
Runtime stage	Like your production server â€” clean, runs only the final binary

You develop and build in one;
You deploy and run in the other.

ğŸ”’ Bonus â€” Security advantage

Less stuff inside = less surface for hackers.
If someone gets into your running container, they canâ€™t even run bash or apt-get.
Itâ€™s a sealed box that just runs one process (java -jar app.jar).


1ï¸âƒ£ The problem: what happens to data in containers?

When you run a container, everything inside it lives in an isolated filesystem.
That filesystem disappears when the container stops or is deleted.

So how do we keep data (e.g. databases, logs, uploads) even after the container is stopped or rebuilt?

Docker gives two main solutions:

1ï¸âƒ£ Volumes â€” managed by Docker
2ï¸âƒ£ Bind mounts â€” linked directly to your local filesystem

What is a Bind Mount?

ğŸ‘‰ A bind mount directly connects a folder on your host machine to a folder inside the container.

Example:

docker run -v /home/user/app:/usr/src/app myimage


Explanation:

/home/user/app â†’ path on your local machine

/usr/src/app â†’ path inside the container

âœ… So if you:

change files on your computer â†’ the container sees it instantly

or change files inside container â†’ you see it on your host

Itâ€™s like a shared folder between your machine and the container.

Typical use case: Local development

For example, when building a Node.js or React app:

docker run -v $(pwd):/app -w /app node:20 npm start


Here:

You edit code in VS Code (on host)

Container runs Node inside /app

Changes reflect instantly (no rebuild needed)

âœ… Thatâ€™s how you can â€œdevelop inside Dockerâ€ without constantly rebuilding images.

What is a Volume?

A Docker volume is a persistent storage location managed by Docker itself, not tied to your local folder structure.

You create it like this:

docker volume create mydata
docker run -v mydata:/var/lib/mysql mysql


mydata â†’ volume name

/var/lib/mysql â†’ path inside container where MySQL stores data

âœ… Docker stores the volumeâ€™s data somewhere inside /var/lib/docker/volumes/ (on Linux),
but you donâ€™t worry about the exact path â€” Docker manages it.

| Feature              | **Bind Mount**                                       | **Volume**                            |
| -------------------- | ---------------------------------------------------- | ------------------------------------- |
| **Where data lives** | On your **host filesystem** (exact path you specify) | In **Docker-managed storage**         |
| **Created by**       | You (manual path)                                    | Docker (`docker volume create`)       |
| **Best for**         | Local development (code sharing)                     | Production (persistent data)          |
| **Performance**      | Slightly slower (depends on FS)                      | Optimized by Docker                   |
| **Backup/migrate**   | Manual                                               | Easy (`docker volume inspect/export`) |
| **Security**         | Risky (access to host paths)                         | Safer, isolated                       |
| **Portability**      | Path-dependent                                       | Portable across systems               |

Host Machine
â”œâ”€â”€ /home/user/project/        <-- bind mount path
â”‚     â”œâ”€â”€ app.js
â”‚     â””â”€â”€ package.json
â”‚
â””â”€â”€ /var/lib/docker/volumes/
      â”œâ”€â”€ mydata/
      â”‚    â””â”€â”€ _data/
      â”‚         â”œâ”€â”€ db files
      â”‚         â””â”€â”€ logs

5ï¸âƒ£ How to manage volumes
docker volume create mydata
docker volume ls
docker volume inspect mydata
docker volume rm mydata

6ï¸âƒ£ Example using Docker Compose

Letâ€™s say you have a web app + MySQL.

version: "3.9"
services:
  app:
    build: .
    ports:
      - "8080:8080"
    volumes:
      - .:/app  # bind mount (for local code)
  db:
    image: mysql:8
    environment:
      MYSQL_ROOT_PASSWORD: secret
    volumes:
      - db_data:/var/lib/mysql  # named volume (for persistent data)

volumes:
  db_data:

âœ… In short:

Bind mounts are for developing â€” share live code.
Volumes are for persisting data â€” survive rebuilds and restarts.


1ï¸âƒ£ Docker networking The core idea

When you start a container, Docker gives it:

Its own network namespace (like a mini isolated LAN)

A private IP address

Controlled routes to other containers or the host

So each container behaves like its own small computer on a virtual network.


2ï¸âƒ£ The default Docker networks

Run:

docker network ls


Youâ€™ll usually see something like:

NETWORK ID     NAME      DRIVER    SCOPE
c3f279d17e0a   bridge    bridge    local
a9a5f10e0ad6   host      host      local
cf03ee007fb1   none      null      local

1. Bridge network (default)

When you do:

docker run -d nginx


Docker automatically connects the container to the default bridge network.

Each container on that network gets:

A private IP (e.g. 172.17.0.2)

Access to other containers on the same bridge

Access to the hostâ€™s internet (via NAT)

Diagram:

Host (Docker)
â”‚
â”œâ”€â”€ docker0 (bridge interface) â†’ 172.17.0.1
â”‚     â”œâ”€â”€ container1 â†’ 172.17.0.2
â”‚     â”œâ”€â”€ container2 â†’ 172.17.0.3
â”‚     â””â”€â”€ ...


âœ… Containers on the same bridge can communicate using IP or container name (if on a custom bridge).

2. Host network

When you run:

docker run --network host nginx


â¡ï¸ The container shares the hostâ€™s network stack.
No private IP â€” it uses the hostâ€™s network directly.

So if your host IP is 192.168.1.10,
your containerâ€™s server also runs on 192.168.1.10.

âœ… Good for performance (no NAT).
âš ï¸ But: less isolation.

Used often for performance-critical or system-level tools (e.g. monitoring agents, Prometheus exporters).

3ï¸âƒ£ Custom bridge networks

You can create your own isolated network:

docker network create myapp_net


Then attach containers:

docker run -d --network myapp_net --name backend my-backend
docker run -d --network myapp_net --name frontend my-frontend


âœ… Containers in myapp_net can resolve each other by name using Dockerâ€™s built-in DNS.

frontend â†’ backend:8080
backend â†’ db:3306


This is how microservices talk to each other inside Docker Compose.

4ï¸âƒ£ How Docker Compose handles networking

When you use docker-compose.yml, Docker automatically creates a custom network for your app:

Example:

version: '3.9'
services:
  backend:
    build: ./backend
    ports:
      - "8080:8080"
  db:
    image: mysql
    environment:
      MYSQL_ROOT_PASSWORD: secret


Compose auto-creates a network (e.g., projectname_default) and connects all services to it.
Then you can connect between services using service names:

backend connects to DB using hostname db:3306

No IP addresses needed

âœ… Built-in DNS service takes care of name resolution.


